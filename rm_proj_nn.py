# -*- coding: utf-8 -*-
"""RM_Proj_NN

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1R65PIVkWB3qxUVb8x5FXPxKI9lkpejPf

Importing libraries
"""

import keras
import time
import numpy as np
import tensorflow as tf
from keras.optimizers import SGD
from keras.models import load_model
from keras.callbacks import ModelCheckpoint
from sklearn.model_selection import train_test_split

from keras.applications.vgg16 import VGG16
from keras.applications.resnet import ResNet50
from keras.applications.densenet import DenseNet121

import matplotlib.pyplot as plt
from sklearn.metrics import classification_report, confusion_matrix

"""Loading image labels"""

# loading image label arrays from drive
train_labels = np.load('/content/drive/MyDrive/FER2013/train_labels.npy')
test_labels = np.load('/content/drive/MyDrive/FER2013/test_labels.npy')

print("Training Labels : ",train_labels.shape)
print("Testing  Labels : ",test_labels.shape)

"""Laoding raw image data"""

# loading raw image arrays from drive
train_data = np.load('/content/drive/MyDrive/FER2013/train_data.npy')
test_data = np.load('/content/drive/MyDrive/FER2013/test_data.npy')

print("Training Data   : ",train_data.shape)
print("Testing  Data   : ",test_data.shape)

"""ResNet50 with Rawdata"""

# Loading pretrain resnet model
resnet_model = ResNet50(weights='imagenet',include_top=False)

# Pooling/ flat
pooling = keras.layers.GlobalAveragePooling2D()(resnet_model.output)

# Adding fully connected layer 1
pred = keras.layers.Dense(7, activation='softmax', name="pred")(pooling)

# Final model
model = keras.models.Model(inputs = resnet_model.input, outputs=pred)

# Options setting
options = keras.optimizers.SGD(learning_rate = 0.001,decay=1e-6,momentum=0.9)

model.compile(optimizer=options, metrics=["accuracy"],loss='categorical_crossentropy')

# saving the best model 
filepath="/content/drive/MyDrive/FER2013/rawdata_resnet50.hdf5"
checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')
callbacks_list = [checkpoint]

# train the model
history = model.fit(train_data, train_labels, batch_size = 64, epochs = 15, shuffle=True, callbacks = callbacks_list, validation_data=(test_data, test_labels))

"""Accuracy and Loss curve for ResNet50 model"""

plt.plot(history.history['accuracy'])
plt.plot(history.history['loss'])
plt.title('model accuracy and loss')
plt.ylabel('accuracy and loss')
plt.xlabel('epoch')
plt.legend(['accuracy', 'loss'], loc='upper right')
plt.show()

"""VGG16 with Rawdata"""

vgg_model = VGG16(weights='imagenet',include_top=False)

# Pooling/ flat
pooling = keras.layers.GlobalAveragePooling2D()(vgg_model.output)

# Adding fully connected layer 1
pred = keras.layers.Dense(7, activation='softmax', name="pred")(pooling)

# Final model
model = keras.models.Model(inputs = vgg_model.input, outputs=pred)

# Options setting
options = keras.optimizers.SGD(learning_rate = 0.001,decay=1e-5,momentum=0.9)

model.compile(optimizer=options, metrics=["accuracy"],loss='categorical_crossentropy')

# saving the best model 
filepath="/content/drive/MyDrive/FER2013/rawdata_VGG16.hdf5"
checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')
callbacks_list = [checkpoint]

# train the model
history = model.fit(train_data, train_labels, batch_size = 64, epochs = 15, shuffle=True, callbacks = callbacks_list, validation_data=(test_data, test_labels))

"""Accuracy and Loss curve for VGG16 model"""

plt.plot(history.history['accuracy'])
plt.plot(history.history['loss'])
plt.title('model accuracy and loss')
plt.ylabel('accuracy and loss')
plt.xlabel('epoch')
plt.legend(['accuracy', 'loss'], loc='upper right')
plt.show()

"""DenseNet121 with Rawdata"""

densenet_model = DenseNet121(weights='imagenet',include_top=False)

# Pooling/ flat
pooling = keras.layers.GlobalAveragePooling2D()(densenet_model.output)

# Adding fully connected layer 1
pred = keras.layers.Dense(7, activation='softmax', name="pred")(pooling)

# Final model
model = keras.models.Model(inputs = densenet_model.input, outputs=pred)

# Options setting
options = keras.optimizers.SGD(learning_rate = 0.001,decay=1e-6,momentum=0.9)

model.compile(optimizer=options, metrics=["accuracy"],loss='categorical_crossentropy')

# saving the best model 
filepath="/content/drive/MyDrive/FER2013/rawdata_dense121.hdf5"
checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')
callbacks_list = [checkpoint]

# train the model
history =  model.fit(train_data, train_labels, batch_size = 64, epochs = 15, shuffle=True, callbacks = callbacks_list, validation_data=(test_data, test_labels))

plt.plot(history.history['accuracy'])
plt.plot(history.history['loss'])
plt.title('model accuracy and loss')
plt.ylabel('accuracy and loss')
plt.xlabel('epoch')
plt.legend(['accuracy', 'loss'], loc='upper right')
plt.show()

"""Ensemble Learning for Rawdata (ResNet50 + VGG16 + DenseNet121)"""

from sklearn.metrics import accuracy_score

resnet_model = load_model("/content/drive/MyDrive/FER2013/rawdata_resnet50.hdf5")
vgg_model = load_model("/content/drive/MyDrive/FER2013/rawdata_vgg16.hdf5")
dense_model = load_model("/content/drive/MyDrive/FER2013/rawdata_dense121.hdf5")

raw_dense = dense_model.predict(test_data)
raw_vgg = vgg_model.predict(test_data)
raw_resnet = resnet_model.predict(test_data)

averaged_preds = np.argmax(raw_dense + raw_vgg + raw_resnet, 1)
real_labels = np.argmax(test_labels, 1)
acc = accuracy_score(real_labels, averaged_preds)
print(acc)

"""Classification report and Confusion Matrix for Raw data"""

from sklearn.metrics import classification_report, confusion_matrix

print("Classification Report :\n")
print(classification_report(real_labels, averaged_preds))

print("Confusion Matrix :\n")
print(confusion_matrix(real_labels, averaged_preds))

"""Loading Sobel filter data"""

# Sobel filtered image arrays
# loading image arrays from drive

train_data = np.load('/content/drive/MyDrive/FER2013/sobel_train.npy')
test_data = np.load('/content/drive/MyDrive/FER2013/sobel_test.npy')

print("Training Data   : ",train_data.shape)
print("Testing  Data   : ",test_data.shape)

"""ResNet50 model with Sobel filtered data"""

resnet_model = ResNet50(weights='imagenet',include_top=False)

# Pooling/ flat
pooling = keras.layers.GlobalAveragePooling2D()(resnet_model.output)

# Adding fully connected layer 1
pred = keras.layers.Dense(7, activation='softmax', name="pred")(pooling)

# Final model
model = keras.models.Model(inputs = resnet_model.input, outputs=pred)

# Options setting
options = keras.optimizers.SGD(learning_rate = 0.001,decay=1e-6,momentum=0.9)

model.compile(optimizer=options, metrics=["accuracy"],loss='categorical_crossentropy')

# saving the best model 
filepath="/content/drive/MyDrive/FER2013/sobel_filt_resnet50.hdf5"
checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')
callbacks_list = [checkpoint]

# train the model
history = model.fit(train_data, train_labels, batch_size = 64, epochs = 15, shuffle=True, callbacks = callbacks_list, validation_data=(test_data, test_labels))

"""Accuracy and Loss curve for ResNet50 model"""

plt.plot(history.history['accuracy'])
plt.plot(history.history['loss'])
plt.title('model accuracy and loss')
plt.ylabel('accuracy and loss')
plt.xlabel('epoch')
plt.legend(['accuracy', 'loss'], loc='upper right')
plt.show()

"""VGG16 model with Sobel filtered data"""

vgg_model = VGG16(weights='imagenet',include_top=False)

# Pooling/ flat
pooling = keras.layers.GlobalAveragePooling2D()(vgg_model.output)

# Adding fully connected layer 1
pred = keras.layers.Dense(7, activation='softmax', name="pred")(pooling)

# Final model
model = keras.models.Model(inputs = vgg_model.input, outputs=pred)

# Options setting
options = keras.optimizers.SGD(learning_rate = 0.001,decay=1e-5,momentum=0.9)

model.compile(optimizer=options, metrics=["accuracy"],loss='categorical_crossentropy')

# saving the best model 
filepath="/content/drive/MyDrive/FER2013/sobel_filt_VGG16.hdf5"
checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')
callbacks_list = [checkpoint]

# train the model
history = model.fit(train_data, train_labels, batch_size = 64, epochs = 15, shuffle=True, callbacks = callbacks_list, validation_data=(test_data, test_labels))

"""Accuracy and Loss curve for VGG16 model"""

plt.plot(history.history['accuracy'])
plt.plot(history.history['loss'])
plt.title('model accuracy and loss')
plt.ylabel('accuracy and loss')
plt.xlabel('epoch')
plt.legend(['accuracy', 'loss'], loc='upper right')
plt.show()

"""DenseNet121 model with Sobel filtered data"""

densenet_model = DenseNet121(weights='imagenet',include_top=False)

# Pooling/ flat
pooling = keras.layers.GlobalAveragePooling2D()(densenet_model.output)

# Adding fully connected layer 1
pred = keras.layers.Dense(7, activation='softmax', name="pred")(pooling)

# Final model
model = keras.models.Model(inputs = densenet_model.input, outputs=pred)

# Options setting
options = keras.optimizers.SGD(learning_rate = 0.001,decay=1e-6,momentum=0.9)

model.compile(optimizer=options, metrics=["accuracy"],loss='categorical_crossentropy')

# saving the best model
filepath="/content/drive/MyDrive/FER2013/sobel_filt_dense121.hdf5"
checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')
callbacks_list = [checkpoint]

# train the model
history = model.fit(train_data, train_labels, batch_size = 64, epochs = 15, shuffle=True, callbacks = callbacks_list, validation_data=(test_data, test_labels))

"""Accuracy and Loss curve for DenseNet121"""

plt.plot(history.history['accuracy'])
plt.plot(history.history['loss'])
plt.title('model accuracy and loss')
plt.ylabel('accuracy and loss')
plt.xlabel('epoch')
plt.legend(['accuracy', 'loss'], loc='upper right')
plt.show()

"""Ensemble Learning for Sobel filtered data (ResNet50 + VGG16 + DenseNet121)"""

from sklearn.metrics import accuracy_score

resnet_model = load_model("/content/drive/MyDrive/FER2013/sobel_filt_resnet50.hdf5")
vgg_model = load_model("/content/drive/MyDrive/FER2013/sobel_filt_vgg16.hdf5")
dense_model = load_model("/content/drive/MyDrive/FER2013/sobel_filt_dense121.hdf5")

sobel_dense = dense_model.predict(test_data)
sobel_vgg = vgg_model.predict(test_data)
sobel_resnet = resnet_model.predict(test_data)

averaged_preds = np.argmax(sobel_dense + sobel_vgg + sobel_resnet, 1)
real_labels = np.argmax(test_labels, 1)
acc = accuracy_score(real_labels, averaged_preds)
print(acc)

"""Classification report and Confusion matrix for Sobel filtered data"""

from sklearn.metrics import classification_report, confusion_matrix

print("Classification Report :\n")
print(classification_report(real_labels, averaged_preds))

print("Confusion Matrix :\n")
print(confusion_matrix(real_labels, averaged_preds))