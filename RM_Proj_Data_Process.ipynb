{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RM_Proj_Data_Process",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BOFZVDVpds7c",
        "outputId": "18e1dd9b-0c51-41eb-ab0a-0d62c15ed48e"
      },
      "source": [
        "from zipfile import ZipFile\n",
        "  \n",
        "zip_file = \"/content/drive/MyDrive/FER2013/archive.zip\"\n",
        "\n",
        "# opening the zip file in READ mode\n",
        "with ZipFile(zip_file, 'r') as zip:\n",
        "    # extracting all the files\n",
        "    print('Extracting files...')\n",
        "    zip.extractall(\"/content/drive/MyDrive/FER2013/\")\n",
        "    print('Done!')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Extracting files...\n",
            "Done!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dx9-_oyseiVi",
        "outputId": "fa072c5e-f699-4185-dd0e-c482a1443f3f"
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "\n",
        "# fetching path for each image in train and test directories\n",
        "def loadData(path):\n",
        "  data = []\n",
        "  labels = []\n",
        "  for folder in os.listdir(path):\n",
        "    for img in os.listdir(path + \"/\" + folder):\n",
        "      data.append((path + \"/\" + folder + \"/\" + img))\n",
        "      labels.append(folder)\n",
        "    print(\"Fetching image path from \",path + \"/\" + folder)\n",
        "  return np.array(data), np.array(labels)\n",
        "\n",
        "train_path, train_labels = loadData(\"/content/drive/MyDrive/FER2013/train\")\n",
        "print(\"\\n\")\n",
        "test_path, test_labels = loadData(\"/content/drive/MyDrive/FER2013/test\")\n",
        "print(\"\\n\")\n",
        "print(\"Training Images : \",train_path.shape)\n",
        "print(\"Training Labels : \",train_labels.shape)\n",
        "print(\"Testing  Images : \",test_path.shape)\n",
        "print(\"Testing  Labels : \",test_labels.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fetching image path from  /content/drive/MyDrive/FER2013/train/angry\n",
            "Fetching image path from  /content/drive/MyDrive/FER2013/train/disgust\n",
            "Fetching image path from  /content/drive/MyDrive/FER2013/train/fear\n",
            "Fetching image path from  /content/drive/MyDrive/FER2013/train/happy\n",
            "Fetching image path from  /content/drive/MyDrive/FER2013/train/neutral\n",
            "Fetching image path from  /content/drive/MyDrive/FER2013/train/sad\n",
            "Fetching image path from  /content/drive/MyDrive/FER2013/train/surprise\n",
            "\n",
            "\n",
            "Fetching image path from  /content/drive/MyDrive/FER2013/test/angry\n",
            "Fetching image path from  /content/drive/MyDrive/FER2013/test/disgust\n",
            "Fetching image path from  /content/drive/MyDrive/FER2013/test/fear\n",
            "Fetching image path from  /content/drive/MyDrive/FER2013/test/happy\n",
            "Fetching image path from  /content/drive/MyDrive/FER2013/test/neutral\n",
            "Fetching image path from  /content/drive/MyDrive/FER2013/test/sad\n",
            "Fetching image path from  /content/drive/MyDrive/FER2013/test/surprise\n",
            "\n",
            "\n",
            "Training Images :  (28709,)\n",
            "Training Labels :  (28709,)\n",
            "Testing  Images :  (7080,)\n",
            "Testing  Labels :  (7080,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jn-eiqAbFcTv"
      },
      "source": [
        "import cv2\n",
        "\n",
        "# using train and test image path loaing image as array into one variable\n",
        "def resizeImages(images):\n",
        "\n",
        "  X = np.ndarray((images.shape[0],224,224,3), dtype=np.uint8)\n",
        "  Y = np.ndarray((images.shape[0],48,48,3), dtype=np.uint8)\n",
        "\n",
        "  for i, img in enumerate(images):\n",
        "    # fetching image from path\n",
        "    imgRead = cv2.imread(img, cv2.IMREAD_COLOR)\n",
        "\n",
        "    # resizing image from 48x48 pixels to 224x224 pixels\n",
        "    X[i, :] = cv2.resize(imgRead, (224, 224), interpolation=cv2.INTER_CUBIC)\n",
        "    Y[i, :] = imgRead\n",
        "\n",
        "    if i%500 == 0:\n",
        "      print(\"Processed Images = {}\".format(i))\n",
        "    if i == (images.shape[0]-1):\n",
        "      print(\"Processed Images = {}\".format(i+1))\n",
        "\n",
        "  return X, Y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qme-2RDipDE-",
        "outputId": "6b89f1dd-fdd8-419e-9f86-2a604de9c0d5"
      },
      "source": [
        "print(\"Processing train data .... \\n\")\n",
        "train_data, train_data48 = resizeImages(train_path)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Processing train data .... \n",
            "\n",
            "Processed Images = 0\n",
            "Processed Images = 500\n",
            "Processed Images = 1000\n",
            "Processed Images = 1500\n",
            "Processed Images = 2000\n",
            "Processed Images = 2500\n",
            "Processed Images = 3000\n",
            "Processed Images = 3500\n",
            "Processed Images = 4000\n",
            "Processed Images = 4500\n",
            "Processed Images = 5000\n",
            "Processed Images = 5500\n",
            "Processed Images = 6000\n",
            "Processed Images = 6500\n",
            "Processed Images = 7000\n",
            "Processed Images = 7500\n",
            "Processed Images = 8000\n",
            "Processed Images = 8500\n",
            "Processed Images = 9000\n",
            "Processed Images = 9500\n",
            "Processed Images = 10000\n",
            "Processed Images = 10500\n",
            "Processed Images = 11000\n",
            "Processed Images = 11500\n",
            "Processed Images = 12000\n",
            "Processed Images = 12500\n",
            "Processed Images = 13000\n",
            "Processed Images = 13500\n",
            "Processed Images = 14000\n",
            "Processed Images = 14500\n",
            "Processed Images = 15000\n",
            "Processed Images = 15500\n",
            "Processed Images = 16000\n",
            "Processed Images = 16500\n",
            "Processed Images = 17000\n",
            "Processed Images = 17500\n",
            "Processed Images = 18000\n",
            "Processed Images = 18500\n",
            "Processed Images = 19000\n",
            "Processed Images = 19500\n",
            "Processed Images = 20000\n",
            "Processed Images = 20500\n",
            "Processed Images = 21000\n",
            "Processed Images = 21500\n",
            "Processed Images = 22000\n",
            "Processed Images = 22500\n",
            "Processed Images = 23000\n",
            "Processed Images = 23500\n",
            "Processed Images = 24000\n",
            "Processed Images = 24500\n",
            "Processed Images = 25000\n",
            "Processed Images = 25500\n",
            "Processed Images = 26000\n",
            "Processed Images = 26500\n",
            "Processed Images = 27000\n",
            "Processed Images = 27500\n",
            "Processed Images = 28000\n",
            "Processed Images = 28500\n",
            "Processed Images = 28709\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aY0e7LZOYuhQ",
        "outputId": "783c1867-237b-4a37-a8cd-5c1fbdaa0604"
      },
      "source": [
        "# suffuling train data\n",
        "shuffler = np.random.permutation(len(train_data))\n",
        "train_data = train_data[shuffler]\n",
        "train_data48 = train_data48[shuffler]\n",
        "train_labels = train_labels[shuffler]\n",
        "\n",
        "# one hot train encode labels\n",
        "unique, inverse = np.unique(train_labels, return_inverse=True)\n",
        "train_labels = np.eye(unique.shape[0])[inverse]\n",
        "print(\"Training Data    : \",train_data.shape)\n",
        "print(\"Training Data(48): \",train_data48.shape)\n",
        "print(\"Training Labels  : \",train_labels.shape)\n",
        "\n",
        "# Saving train images and labels into .npy file\n",
        "np.save('/content/drive/MyDrive/FER2013/train_data.npy', train_data)\n",
        "np.save('/content/drive/MyDrive/FER2013/train_data48.npy', train_data48)\n",
        "np.save('/content/drive/MyDrive/FER2013/train_labels.npy', train_labels)\n",
        "\n",
        "del train_data48"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training Data    :  (28709, 224, 224, 3)\n",
            "Training Data(48):  (28709, 48, 48, 3)\n",
            "Training Labels  :  (28709, 7)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MA0nJ3XnZJTw"
      },
      "source": [
        "def sobelEdgeDetection(img):\n",
        "  scale = 1\n",
        "  delta = 0\n",
        "  ddepth = cv2.CV_16S\n",
        "\n",
        "  grad_x = cv2.Sobel(img, ddepth, 1, 0, ksize=3, scale=scale, delta=delta, borderType=cv2.BORDER_DEFAULT)\n",
        "  grad_y = cv2.Sobel(img, ddepth, 0, 1, ksize=3, scale=scale, delta=delta, borderType=cv2.BORDER_DEFAULT)\n",
        "\n",
        "  abs_grad_x = cv2.convertScaleAbs(grad_x)\n",
        "  abs_grad_y = cv2.convertScaleAbs(grad_y)\n",
        "  \n",
        "  image_edges = cv2.addWeighted(abs_grad_x, 0.5, abs_grad_y, 0.5, 0)\n",
        "  return image_edges"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P9MKJUfNZbLS"
      },
      "source": [
        "train_canny_edges = np.ndarray((train_data.shape[0],224,224), dtype=np.uint8)\n",
        "train_sobel_edges = np.ndarray((train_data.shape[0],224,224,3), dtype=np.uint8)\n",
        "\n",
        "for i in range(len(train_data)):\n",
        "  \n",
        "  # applying canny edge detector\n",
        "  train_canny_edges[i, :] = cv2.Canny(train_data[i],70,100)\n",
        "  \n",
        "  # applying sobel edge detector\n",
        "  train_sobel_edges[i, :] = sobelEdgeDetection(train_data[i])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TeHBOvs0aHdz"
      },
      "source": [
        "# Saving filtered train images into .npy file\n",
        "np.save(\"/content/drive/MyDrive/FER2013/sobel_train.npy\",train_sobel_edges)\n",
        "np.save(\"/content/drive/MyDrive/FER2013/canny_train.npy\",train_canny_edges)\n",
        "\n",
        "del train_data\n",
        "del train_sobel_edges\n",
        "del train_canny_edges"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2PMoUaaNaDfk",
        "outputId": "b5a44b55-d73d-4bd1-f9b9-fe55de3487e2"
      },
      "source": [
        "print(\"Processing test data .... \\n\")\n",
        "test_data, test_data48 = resizeImages(test_path)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Processing test data .... \n",
            "\n",
            "Processed Images = 0\n",
            "Processed Images = 500\n",
            "Processed Images = 1000\n",
            "Processed Images = 1500\n",
            "Processed Images = 2000\n",
            "Processed Images = 2500\n",
            "Processed Images = 3000\n",
            "Processed Images = 3500\n",
            "Processed Images = 4000\n",
            "Processed Images = 4500\n",
            "Processed Images = 5000\n",
            "Processed Images = 5500\n",
            "Processed Images = 6000\n",
            "Processed Images = 6500\n",
            "Processed Images = 7000\n",
            "Processed Images = 7080\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F7MJWHeDZIoB",
        "outputId": "d67d6dc4-f432-4758-811c-c9ed5d09d459"
      },
      "source": [
        "# suffuling test data\n",
        "shuffler = np.random.permutation(len(test_data))\n",
        "test_data = test_data[shuffler]\n",
        "test_data48 = test_data48[shuffler]\n",
        "test_labels = test_labels[shuffler]\n",
        "\n",
        "# one hot test encode labels\n",
        "unique, inverse = np.unique(test_labels, return_inverse=True)\n",
        "test_labels = np.eye(unique.shape[0])[inverse]\n",
        "print(\"Testing  Data    : \",test_data.shape)\n",
        "print(\"Testing  Data(48): \",test_data48.shape)\n",
        "print(\"Testing  Labels  : \",test_labels.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Testing  Data    :  (7080, 224, 224, 3)\n",
            "Testing  Data(48):  (7080, 48, 48, 3)\n",
            "Testing  Labels  :  (7080, 7)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VXo32G9ab9_0"
      },
      "source": [
        "# Saving test images and labels into .npy file\n",
        "np.save('/content/drive/MyDrive/FER2013/test_data.npy', test_data)\n",
        "np.save('/content/drive/MyDrive/FER2013/test_data48.npy', test_data48)\n",
        "np.save('/content/drive/MyDrive/FER2013/test_labels.npy', test_labels)\n",
        "\n",
        "del test_data48"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q8YjsO03YU29"
      },
      "source": [
        "test_canny_edges = np.ndarray((test_data.shape[0],224,224), dtype=np.uint8)\n",
        "test_sobel_edges = np.ndarray((test_data.shape[0],224,224,3), dtype=np.uint8)\n",
        "\n",
        "for i in range(len(test_data)):\n",
        "  \n",
        "  # applying canny edge detector\n",
        "  test_canny_edges[i, :] = cv2.Canny(test_data[i],70,100)\n",
        "  \n",
        "  # applying sobel edge detector\n",
        "  test_sobel_edges[i, :] = sobelEdgeDetection(test_data[i])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TjdnOiWWJez2"
      },
      "source": [
        "np.save(\"/content/drive/MyDrive/FER2013/sobel_test.npy\",test_sobel_edges)\n",
        "np.save(\"/content/drive/MyDrive/FER2013/canny_test.npy\",test_canny_edges)\n",
        "\n",
        "del test_data\n",
        "del test_sobel_edges\n",
        "del test_canny_edges"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}